{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from random import shuffle\n",
    "\n",
    "df = pd.read_csv('train.tsv', sep='\\t')\n",
    "\n",
    "train_size = 0.8\n",
    "data_size = 10000\n",
    "\n",
    "df = df[:data_size]\n",
    "train = df[:int(data_size*0.8)].sample(frac=1)\n",
    "dev = df[int(data_size*0.8):].sample(frac=1).reset_index()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : prétraitements\n",
    "#StopList, integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "text_data = train[\"Phrase\"]\n",
    "vectorizer.fit(text_data)\n",
    "voca = vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.24 s, sys: 613 ms, total: 2.86 s\n",
      "Wall time: 2.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word2index = {i:w for w,i in enumerate(voca)}\n",
    "\n",
    "def s2v(ohvS, pad):    \n",
    "    y = torch.tensor(ohvS).unsqueeze(1)\n",
    "    onehot = torch.zeros(len(y), len(voca))\n",
    "#     Prend en compte les phrases n'ayant que des mots non présents dans le voca ('the')\n",
    "# devrait être géré après prétraitrements\n",
    "    if len(ohvS) > 0:\n",
    "        onehot.scatter_(1, y, 1)\n",
    "    paddingT = torch.zeros(1, len(voca))\n",
    "    for i in range(len(ohvS), pad):\n",
    "        onehot = torch.cat((onehot, paddingT), 0)\n",
    "    return onehot\n",
    "    \n",
    "def sentence2index(sent, voca, dic):\n",
    "    return [dic[w] for w in set(sent.split()).intersection(voca)]\n",
    "\n",
    "train_data = text_data.apply(lambda x : sentence2index(x, voca, word2index))\n",
    "longestSentence = train_data.apply(lambda x : len(x)).max()\n",
    "text_tensor_train = train_data.apply(lambda x : s2v(x, longestSentence))\n",
    "\n",
    "#ajout du cas où on ne connait pas le mot\n",
    "# voca = vectorizer.get_feature_names() + list(['<unk>'])\n",
    "#ajout d'un zéro à la fin de chaque tensor\n",
    "# unk = torch.zeros([text_tensor_train.shape[0],1], dtype=torch.float)\n",
    "# text_tensor_train = torch.cat((text_tensor_train, unk), 1).unsqueeze(1)\n",
    "\n",
    "def labelToVec(label):\n",
    "    # label_one_hot_vector = torch.tensor(pd.get_dummies(df[\"Sentiment\"]).values)\n",
    "    label_tensor = torch.tensor(label[\"Sentiment\"].values)\n",
    "    return label_tensor\n",
    "\n",
    "label_tensor_train = labelToVec(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#Ne prend pas en compte <unk>\n",
    "\n",
    "dev_data = dev['Phrase'].apply(lambda x : sentence2index(x, voca, word2index))\n",
    "text_tensor_dev = dev_data.apply(lambda x : s2v(x, longestSentence))\n",
    "\n",
    "label_tensor_dev = labelToVec(dev)\n",
    "\n",
    "print(type(text_tensor_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DF to tensor\n",
    "\n",
    "text_tensor_train = torch.cat(([t.unsqueeze(0) for t in text_tensor_train]), 0)\n",
    "text_tensor_dev = torch.cat(([t.unsqueeze(0) for t in text_tensor_dev]), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "\n",
    "        self.rnn = nn.RNN(input_size = input_size, hidden_size = hidden_size, batch_first = True)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)       \n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        hidden = self.initHidden(input.shape[0]).to(device)        \n",
    "        output, hidden = self.rnn(input, hidden)\n",
    "        output = self.h2o(hidden[0])\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_dim = len(voca)\n",
    "embedding_size = 100\n",
    "hidden_dim = 128\n",
    "output_dim = 5\n",
    "\n",
    "rnn = RNN(input_dim, embedding_size, hidden_dim, output_dim)\n",
    "\n",
    "rnn = rnn.to(device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adadelta(rnn.parameters(), lr=0.1)\n",
    "\n",
    "def trainRNN(train_category, train_text, dev_category, dev_text, num_epoch, batch_size):\n",
    "    \n",
    "    print(len(voca))\n",
    "    print(train_text.shape)\n",
    "    #un jour je ferais un truc propre\n",
    "    size_train = train_text.size(0)\n",
    "    size_dev = dev_text.size(0)\n",
    "    \n",
    "    hidden = rnn.initHidden(batch_size) \n",
    "    \n",
    "    #TODO vecteur de poids (ici approche \"naïve\")\n",
    "    weight = torch.tensor([1, 0.23, 0.07, 0.2, 0.76])\n",
    "    criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "    \n",
    "    total_pred = torch.tensor([], dtype = torch.long).to(device)\n",
    "    total_targ = torch.tensor([], dtype = torch.long).to(device)\n",
    "    \n",
    "    train_loss = np.zeros(num_epoch)\n",
    "    train_acc = np.zeros(num_epoch)\n",
    "    dev_loss = np.zeros(num_epoch)\n",
    "    dev_acc = np.zeros(num_epoch)\n",
    " \n",
    "    for epoch in range(num_epoch):\n",
    "        nb_batch_train = len(train_text) / batch_size\n",
    "        nb_batch_dev = len(dev_text) / batch_size\n",
    "\n",
    "        i = 0\n",
    "        while (i + batch_size) <= size_train:\n",
    "            tmp = i\n",
    "            i += batch_size\n",
    "            input = train_text[tmp:i].to(device)\n",
    "            target = train_category[tmp:i].to(device)\n",
    "            output = rnn(input)      \n",
    "            \n",
    "            # ?\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output.squeeze(0), target)\n",
    "            loss.backward()\n",
    "            \n",
    "            #TODO Tester sans\n",
    "#             torch.nn.utils.clip_grad_norm_(rnn.parameters(),0.5)\n",
    "            optimizer.step() \n",
    "            \n",
    "            predicted = torch.argmax(output.data, dim=1)\n",
    "            correct = (predicted == target).sum().item()\n",
    "            \n",
    "            train_loss[epoch]  += loss.item()\n",
    "            train_acc[epoch] += correct / batch_size\n",
    "        \n",
    "        i = 0        \n",
    "        #j'aime faire des boucles presque pareilles\n",
    "        while (i + batch_size) <= size_dev:\n",
    "            tmp = i\n",
    "            i += batch_size\n",
    "            input = dev_text[tmp:i].to(device)\n",
    "            target = dev_category[tmp:i].to(device)\n",
    "            \n",
    "            output = rnn(input)\n",
    "            loss = criterion(output.squeeze(0), target)   \n",
    "            \n",
    "            predicted = torch.argmax(output.data, dim=1)\n",
    "            correct = (predicted == target).sum().item()\n",
    "            \n",
    "            dev_loss[epoch] += loss.item()\n",
    "            dev_acc[epoch] += correct / batch_size\n",
    "            \n",
    "            #dernière epoch\n",
    "            if epoch + 1 == num_epoch:\n",
    "                total_pred = torch.cat((total_pred, predicted), 0)\n",
    "                total_targ = torch.cat((total_targ, target), 0)\n",
    "        \n",
    "        # keep best rnn (if acc_act > best_act then best_rnn = actual_rnn)\n",
    "        \n",
    "        train_loss[epoch] = train_loss[epoch] / nb_batch_train\n",
    "        train_acc[epoch] = train_acc[epoch] / nb_batch_train\n",
    "        dev_loss[epoch] = dev_loss[epoch] / nb_batch_dev\n",
    "        dev_acc[epoch] = dev_acc[epoch] / nb_batch_dev\n",
    " \n",
    "        print(epoch, \"loss :\", train_loss[epoch], \"/ acc :\", train_acc[epoch])\n",
    "        print(\"Dev loss :\", dev_loss[epoch], \"/ acc :\", dev_acc[epoch])\n",
    "        \n",
    "    print('Fini !')\n",
    "    \n",
    "    return total_pred, total_targ, train_acc, dev_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2145\n",
      "torch.Size([8000, 32, 2145])\n",
      "0 loss : 1.6094672732055186 / acc : 0.5307499999999999\n",
      "Dev loss : 1.6118031293153763 / acc : 0.5539999999999999\n",
      "1 loss : 1.6085069745779037 / acc : 0.5662499999999997\n",
      "Dev loss : 1.6119761914014816 / acc : 0.5539999999999999\n",
      "2 loss : 1.6084245294332504 / acc : 0.5662499999999997\n",
      "Dev loss : 1.6119036436080934 / acc : 0.5539999999999999\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a163bbb7f41a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainAcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevAcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_tensor_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_tensor_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tensor_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_tensor_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-40a07155ef3b>\u001b[0m in \u001b[0;36mtrainRNN\u001b[0;34m(train_category, train_text, dev_category, dev_text, num_epoch, batch_size)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m#TODO Tester sans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/noadkoko/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/noadkoko/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "nb_epoch = 10\n",
    "\n",
    "pred, real, trainAcc, devAcc = trainRNN(label_tensor_train, text_tensor_train, label_tensor_dev, text_tensor_dev, nb_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "0     295\n",
      "1    1307\n",
      "2    4530\n",
      "3    1478\n",
      "4     390\n",
      "Name: Sentiment, dtype: int64\n",
      "Sentiment\n",
      "0      86\n",
      "1     326\n",
      "2    1108\n",
      "3     382\n",
      "4      98\n",
      "Name: Sentiment, dtype: int64\n",
      "Predicted  0  1     2  3  4  __all__\n",
      "Actual                              \n",
      "0          0  0    86  0  0       86\n",
      "1          0  0   326  0  0      326\n",
      "2          0  0  1108  0  0     1108\n",
      "3          0  0   382  0  0      382\n",
      "4          0  0    98  0  0       98\n",
      "__all__    0  0  2000  0  0     2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noadkoko/.local/lib/python3.6/site-packages/pandas_ml/confusion_matrix/abstract.py:66: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  df = df.loc[idx, idx.copy()].fillna(0)  # if some columns or rows are missing\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "print(train.groupby('Sentiment')[\"Sentiment\"].count())\n",
    "print(dev.groupby('Sentiment')[\"Sentiment\"].count())\n",
    "\n",
    "real = real.cpu().data\n",
    "pred = pred.cpu().view(len(real)).data #pred.cpu().squeeze(0)\n",
    "#warning chiante, mais np\n",
    "cm = ConfusionMatrix(real, pred)\n",
    "confusion_matrix(real, pred)\n",
    "print(cm)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1,nb_epoch+1), devAcc, range(1,nb_epoch+1), trainAcc)\n",
    "plt.show()\n",
    "plt.savefig('acc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
