{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from random import shuffle\n",
    "\n",
    "df = pd.read_csv('train_cl.tsv', sep='\\t')\n",
    "\n",
    "train_size = 0.8\n",
    "data_size = 10000\n",
    "df = df[:data_size]\n",
    "\n",
    "train = df[:int(data_size*0.8)].sample(frac=1)\n",
    "dev = df[int(data_size*0.8):].sample(frac=1).reset_index()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "text_data = train[\"Phrase\"]\n",
    "vectorizer.fit(text_data)\n",
    "voca = vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.63 s, sys: 1.09 s, total: 3.72 s\n",
      "Wall time: 3.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word2index = {i:w for w,i in enumerate(voca)}\n",
    "\n",
    "def s2v(ohvS, pad):    \n",
    "    y = torch.tensor(ohvS).unsqueeze(1)\n",
    "    onehot = torch.zeros(len(y), len(voca))\n",
    "#     Prend en compte les phrases n'ayant que des mots non présents dans le voca ('the')\n",
    "# devrait être géré après prétraitrements\n",
    "    if len(ohvS) > 0:\n",
    "        onehot.scatter_(1, y, 1)\n",
    "    paddingT = torch.zeros(1, len(voca))\n",
    "    for i in range(len(ohvS), pad):\n",
    "        onehot = torch.cat((onehot, paddingT), 0)\n",
    "    return onehot\n",
    "    \n",
    "def sentence2index(sent, voca, dic):\n",
    "    return [dic[w] for w in set(sent.split()).intersection(voca)]\n",
    "\n",
    "train_data = text_data.apply(lambda x : sentence2index(x, voca, word2index))\n",
    "longestSentence = train_data.apply(lambda x : len(x)).max()\n",
    "text_tensor_train = train_data.apply(lambda x : s2v(x, longestSentence))\n",
    "\n",
    "#ajout du cas où on ne connait pas le mot\n",
    "# voca = vectorizer.get_feature_names() + list(['<unk>'])\n",
    "#ajout d'un zéro à la fin de chaque tensor\n",
    "# unk = torch.zeros([text_tensor_train.shape[0],1], dtype=torch.float)\n",
    "# text_tensor_train = torch.cat((text_tensor_train, unk), 1).unsqueeze(1)\n",
    "\n",
    "def labelToVec(label):\n",
    "    # label_one_hot_vector = torch.tensor(pd.get_dummies(df[\"Sentiment\"]).values)\n",
    "    label_tensor = torch.tensor(label[\"Sentiment\"].values)\n",
    "    return label_tensor\n",
    "\n",
    "label_tensor_train = labelToVec(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#Ne prend pas en compte <unk>\n",
    "\n",
    "dev_data = dev['Phrase'].apply(lambda x : sentence2index(x, voca, word2index))\n",
    "text_tensor_dev = dev_data.apply(lambda x : s2v(x, longestSentence))\n",
    "\n",
    "label_tensor_dev = labelToVec(dev)\n",
    "\n",
    "print(type(text_tensor_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DF to tensor\n",
    "\n",
    "text_tensor_train = torch.cat(([t.unsqueeze(0) for t in text_tensor_train]), 0)\n",
    "text_tensor_dev = torch.cat(([t.unsqueeze(0) for t in text_tensor_dev]), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "\n",
    "        self.rnn = nn.RNN(input_size = input_size, hidden_size = hidden_size, batch_first = True)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size) \n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        hidden = self.initHidden(input.shape[0]).to(device)        \n",
    "        output, hidden = self.rnn(input)\n",
    "        output = self.h2o(hidden[0])\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_dim = len(voca)\n",
    "embedding_size = 100\n",
    "hidden_dim = 128\n",
    "output_dim = 5\n",
    "\n",
    "rnn = RNN(input_dim, embedding_size, hidden_dim, output_dim)\n",
    "\n",
    "rnn = rnn.to(device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adadelta(rnn.parameters(), lr=0.1)\n",
    "\n",
    "def trainRNN(train_category, train_text, dev_category, dev_text, num_epoch, batch_size):\n",
    "    \n",
    "    #un jour je ferais un truc propre\n",
    "    size_train = train_text.size(0)\n",
    "    size_dev = dev_text.size(0)\n",
    "    \n",
    "    hidden = rnn.initHidden(batch_size) \n",
    "    \n",
    "    #TODO vecteur de poids (ici approche \"naïve\")\n",
    "    weight = torch.tensor([1, 0.23, 0.07, 0.2, 0.76])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    total_pred = torch.tensor([], dtype = torch.long).to(device)\n",
    "    total_targ = torch.tensor([], dtype = torch.long).to(device)\n",
    "    \n",
    "    train_loss = np.zeros(num_epoch)\n",
    "    train_acc = np.zeros(num_epoch)\n",
    "    dev_loss = np.zeros(num_epoch)\n",
    "    dev_acc = np.zeros(num_epoch)\n",
    " \n",
    "    for epoch in range(num_epoch):\n",
    "        nb_batch_train = len(train_text) / batch_size\n",
    "        nb_batch_dev = len(dev_text) / batch_size\n",
    "\n",
    "        i = 0\n",
    "        while (i + batch_size) <= size_train:\n",
    "            tmp = i\n",
    "            i += batch_size\n",
    "            input = train_text[tmp:i].to(device)\n",
    "            target = train_category[tmp:i].to(device)\n",
    "            output = rnn(input)\n",
    "            \n",
    "            loss = criterion(output.squeeze(0), target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(rnn.parameters(),0.5)\n",
    "            optimizer.step() \n",
    "            \n",
    "            predicted = torch.argmax(output.data, dim=1)\n",
    "            correct = (predicted == target).sum().item()\n",
    "            \n",
    "            train_loss[epoch]  += loss.item()\n",
    "            train_acc[epoch] += correct / batch_size\n",
    "        \n",
    "        i = 0        \n",
    "        #j'aime faire des boucles presque pareilles\n",
    "        while (i + batch_size) <= size_dev:\n",
    "            tmp = i\n",
    "            i += batch_size\n",
    "            input = dev_text[tmp:i].to(device)\n",
    "            target = dev_category[tmp:i].to(device)\n",
    "            \n",
    "            output = rnn(input)\n",
    "            loss = criterion(output.squeeze(0), target)   \n",
    "            \n",
    "            predicted = torch.argmax(output.data, dim=1)\n",
    "            correct = (predicted == target).sum().item()\n",
    "            \n",
    "            dev_loss[epoch] += loss.item()\n",
    "            dev_acc[epoch] += correct / batch_size\n",
    "            \n",
    "            #dernière epoch\n",
    "            if epoch + 1 == num_epoch:\n",
    "                total_pred = torch.cat((total_pred, predicted), 0)\n",
    "                total_targ = torch.cat((total_targ, target), 0)\n",
    "        \n",
    "        # keep best rnn (if acc_act > best_act then best_rnn = actual_rnn)\n",
    "        \n",
    "        train_loss[epoch] = train_loss[epoch] / nb_batch_train\n",
    "        train_acc[epoch] = train_acc[epoch] / nb_batch_train\n",
    "        dev_loss[epoch] = dev_loss[epoch] / nb_batch_dev\n",
    "        dev_acc[epoch] = dev_acc[epoch] / nb_batch_dev\n",
    " \n",
    "        print(epoch, \"Train loss :\", train_loss[epoch], \"/ acc :\", train_acc[epoch])\n",
    "        print(\"Dev loss :\", dev_loss[epoch], \"/ acc :\", dev_acc[epoch])\n",
    "        \n",
    "    print('Fini !')\n",
    "    \n",
    "    return total_pred, total_targ, train_acc, dev_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train loss : 1.2371481854468585 / acc : 0.5437500000000002\n",
      "Dev loss : 1.188498255610466 / acc : 0.5690000000000001\n",
      "1 Train loss : 1.1944368071854115 / acc : 0.5683750000000002\n",
      "Dev loss : 1.1886428862810134 / acc : 0.5690000000000001\n",
      "2 Train loss : 1.1942561119794846 / acc : 0.5683750000000002\n",
      "Dev loss : 1.188672623038292 / acc : 0.5690000000000001\n",
      "3 Train loss : 1.194158310815692 / acc : 0.5683750000000002\n",
      "Dev loss : 1.1886878699064254 / acc : 0.5690000000000001\n",
      "4 Train loss : 1.1940782234072684 / acc : 0.5683750000000002\n",
      "Dev loss : 1.188696312904358 / acc : 0.5690000000000001\n",
      "5 Train loss : 1.1940058834850789 / acc : 0.5683750000000002\n",
      "Dev loss : 1.1886985540390014 / acc : 0.5690000000000001\n",
      "6 Train loss : 1.1939388755708933 / acc : 0.5683750000000002\n",
      "Dev loss : 1.188695451617241 / acc : 0.5690000000000001\n",
      "7 Train loss : 1.1938761975616217 / acc : 0.5683750000000002\n",
      "Dev loss : 1.1886870831251144 / acc : 0.5690000000000001\n",
      "8 Train loss : 1.1938172630965709 / acc : 0.5683750000000002\n",
      "Dev loss : 1.188675183057785 / acc : 0.5690000000000001\n",
      "9 Train loss : 1.193761843442917 / acc : 0.5683750000000002\n",
      "Dev loss : 1.188658744096756 / acc : 0.5690000000000001\n",
      "Fini !\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "nb_epoch = 10\n",
    "\n",
    "pred, real, trainAcc, devAcc = trainRNN(label_tensor_train, text_tensor_train, label_tensor_dev, text_tensor_dev, nb_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "0     269\n",
      "1    1284\n",
      "2    4547\n",
      "3    1507\n",
      "4     393\n",
      "Name: Sentiment, dtype: int64\n",
      "Sentiment\n",
      "0      60\n",
      "1     273\n",
      "2    1138\n",
      "3     423\n",
      "4     106\n",
      "Name: Sentiment, dtype: int64\n",
      "Predicted  0  1     2  3  4  __all__\n",
      "Actual                              \n",
      "0          0  0    60  0  0       60\n",
      "1          0  0   273  0  0      273\n",
      "2          0  0  1138  0  0     1138\n",
      "3          0  0   423  0  0      423\n",
      "4          0  0   106  0  0      106\n",
      "__all__    0  0  2000  0  0     2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noadkoko/.local/lib/python3.6/site-packages/pandas_ml/confusion_matrix/abstract.py:66: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  df = df.loc[idx, idx.copy()].fillna(0)  # if some columns or rows are missing\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "print(train.groupby('Sentiment')[\"Sentiment\"].count())\n",
    "print(dev.groupby('Sentiment')[\"Sentiment\"].count())\n",
    "\n",
    "real = real.cpu().data\n",
    "pred = pred.cpu().view(len(real)).data #pred.cpu().squeeze(0)\n",
    "#warning chiante, mais np\n",
    "cm = ConfusionMatrix(real, pred)\n",
    "confusion_matrix(real, pred)\n",
    "print(cm)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1,nb_epoch+1), devAcc, range(1,nb_epoch+1), trainAcc)\n",
    "plt.show()\n",
    "plt.savefig('acc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
